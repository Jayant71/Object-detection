{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T16:36:17.971665Z",
     "start_time": "2024-03-13T16:36:16.446305Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0+cu118\n",
      "2.0.1\n",
      "3.3.0\n",
      "0.6.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from torch import __version__ as torch_version\n",
    "print(torch_version)\n",
    "\n",
    "from mmcv import __version__ as mmcv_version\n",
    "print(mmcv_version)\n",
    "\n",
    "from mmdet import __version__ as mmdet_version\n",
    "print(mmdet_version)\n",
    "\n",
    "from mmyolo import __version__\n",
    "print(__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58165f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.chdir (\"/workspace/objectdet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad10bf9f1f146f3a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T16:38:27.249240Z",
     "start_time": "2024-03-13T16:38:27.226487Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from mmengine.config import Config\n",
    "\n",
    "cfg = Config.fromfile(\"mmyolo/configs/yolov5/yolov5_n-v61_syncbn_fast_8xb16-300e_coco.py\")\n",
    "cfg['data_root'] = \"datasets/Box-1/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1477ce8b5d72854",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T16:38:28.393154Z",
     "start_time": "2024-03-13T16:38:28.388076Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cfg.train_batch_per_gpu = 8\n",
    "\n",
    "# cfg.data_root = \"dataset/Cardboard-3/\"\n",
    "\n",
    "cfg.train_ann_file = 'train/_annotations.coco.json'\n",
    "cfg.train_data_prefix = 'train/'  # Prefix of train image path\n",
    "# Path of val annotation file\n",
    "cfg.val_ann_file = 'valid/_annotations.coco.json'\n",
    "cfg.val_data_prefix = 'valid/'  # Prefix of val image path\n",
    "\n",
    "cfg.num_classes = 1  # Number of classes for classification\n",
    "\n",
    "cfg.optim_wrapper = dict(\n",
    "    type='OptimWrapper',\n",
    "    optimizer=dict(\n",
    "        type='SGD',\n",
    "        lr=2e-1,\n",
    "        momentum=0.937,\n",
    "        weight_decay=cfg.weight_decay,\n",
    "        nesterov=True,\n",
    "        batch_size_per_gpu=cfg.train_batch_size_per_gpu),\n",
    "        constructor='YOLOv5OptimizerConstructor')\n",
    "\n",
    "cfg.default_hooks = dict(\n",
    "    param_scheduler=dict(\n",
    "        type='YOLOv5ParamSchedulerHook',\n",
    "        scheduler_type='linear',\n",
    "        lr_factor=cfg.lr_factor,\n",
    "        max_epochs=50),\n",
    "    checkpoint=dict(\n",
    "        type='CheckpointHook',\n",
    "        interval=10,\n",
    "        save_best='auto',\n",
    "        max_keep_ckpts=3))\n",
    "\n",
    "cfg.model.bbox_head.head_module.num_classes = cfg.num_classes\n",
    "cfg.model.bbox_head.loss_cls.loss_weight = cfg.loss_cls_weight * (cfg.num_classes / 80 * 3 / cfg.num_det_layers)\n",
    "\n",
    "metainfo = dict(\n",
    "    classes = ('Box',),\n",
    "    palette = [\n",
    "        (220, 20, 60),\n",
    "    ]\n",
    ")\n",
    "\n",
    "cfg.train_dataloader.batch_size = 8\n",
    "cfg.train_dataloader.num_workers = 2\n",
    "cfg.train_dataloader.dataset = dict(\n",
    "     type=cfg.dataset_type,\n",
    "        data_root=cfg.data_root,\n",
    "        metainfo=metainfo,\n",
    "        ann_file=cfg.train_ann_file,\n",
    "        data_prefix=dict(img=cfg.train_data_prefix),\n",
    "        filter_cfg=dict(filter_empty_gt=False, min_size=32),\n",
    "        pipeline=cfg.train_pipeline\n",
    ")\n",
    "\n",
    "cfg.val_dataloader.batch_size = 1\n",
    "cfg.val_dataloader.num_workers = 2\n",
    "cfg.val_dataloader.dataset = dict(\n",
    "        type=cfg.dataset_type,\n",
    "        data_root=cfg.data_root,\n",
    "        metainfo=metainfo,\n",
    "        test_mode=True,\n",
    "        data_prefix=dict(img=cfg.val_data_prefix),\n",
    "        ann_file=cfg.val_ann_file,\n",
    "        pipeline=cfg.test_pipeline,\n",
    "        batch_shapes_cfg=cfg.batch_shapes_cfg)\n",
    "\n",
    "# cfg.load_from = \"/home/jayant/Projects/mmdetection/latest/work_dirs/yolov5_n-v61_syncbn_fast_1xb8-300e_cardboard/epoch_90.pth\"\n",
    "cfg.resume = True\n",
    "cfg.val_evaluator = dict(\n",
    "    type='mmdet.CocoMetric',\n",
    "    proposal_nums=(100, 1, 10),\n",
    "    ann_file=cfg.data_root + cfg.val_ann_file,\n",
    "    metric='bbox')\n",
    "\n",
    "cfg.train_cfg = dict(\n",
    "    type='EpochBasedTrainLoop',\n",
    "    max_epochs=50,\n",
    "    val_interval=1)\n",
    "\n",
    "cfg.work_dir = './work_dirs/yolov5_n-v61_syncbn_fast_1xb8-300e_box/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3eb276f7e4a71b69",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T16:38:33.646280Z",
     "start_time": "2024-03-13T16:38:33.642458Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Config (path: mmyolo/configs/yolov5/yolov5_n-v61_syncbn_fast_8xb16-300e_coco.py): {'default_scope': 'mmyolo', 'default_hooks': {'param_scheduler': {'type': 'YOLOv5ParamSchedulerHook', 'scheduler_type': 'linear', 'lr_factor': 0.01, 'max_epochs': 50}, 'checkpoint': {'type': 'CheckpointHook', 'interval': 10, 'save_best': 'auto', 'max_keep_ckpts': 3}}, 'env_cfg': {'cudnn_benchmark': True, 'mp_cfg': {'mp_start_method': 'fork', 'opencv_num_threads': 0}, 'dist_cfg': {'backend': 'nccl'}}, 'vis_backends': [{'type': 'LocalVisBackend'}], 'visualizer': {'type': 'mmdet.DetLocalVisualizer', 'vis_backends': [{'type': 'LocalVisBackend'}], 'name': 'visualizer'}, 'log_processor': {'type': 'LogProcessor', 'window_size': 50, 'by_epoch': True}, 'log_level': 'INFO', 'load_from': None, 'resume': True, 'backend_args': None, '_backend_args': None, 'tta_model': {'type': 'mmdet.DetTTAModel', 'tta_cfg': {'nms': {'type': 'nms', 'iou_threshold': 0.65}, 'max_per_img': 300}}, 'img_scales': [(640, 640), (320, 320), (960, 960)], '_multiscale_resize_transforms': [{'type': 'Compose', 'transforms': [{'type': 'YOLOv5KeepRatioResize', 'scale': (640, 640)}, {'type': 'LetterResize', 'scale': (640, 640), 'allow_scale_up': False, 'pad_val': {'img': 114}}]}, {'type': 'Compose', 'transforms': [{'type': 'YOLOv5KeepRatioResize', 'scale': (320, 320)}, {'type': 'LetterResize', 'scale': (320, 320), 'allow_scale_up': False, 'pad_val': {'img': 114}}]}, {'type': 'Compose', 'transforms': [{'type': 'YOLOv5KeepRatioResize', 'scale': (960, 960)}, {'type': 'LetterResize', 'scale': (960, 960), 'allow_scale_up': False, 'pad_val': {'img': 114}}]}], 'tta_pipeline': [{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'TestTimeAug', 'transforms': [[{'type': 'Compose', 'transforms': [{'type': 'YOLOv5KeepRatioResize', 'scale': (640, 640)}, {'type': 'LetterResize', 'scale': (640, 640), 'allow_scale_up': False, 'pad_val': {'img': 114}}]}, {'type': 'Compose', 'transforms': [{'type': 'YOLOv5KeepRatioResize', 'scale': (320, 320)}, {'type': 'LetterResize', 'scale': (320, 320), 'allow_scale_up': False, 'pad_val': {'img': 114}}]}, {'type': 'Compose', 'transforms': [{'type': 'YOLOv5KeepRatioResize', 'scale': (960, 960)}, {'type': 'LetterResize', 'scale': (960, 960), 'allow_scale_up': False, 'pad_val': {'img': 114}}]}], [{'type': 'mmdet.RandomFlip', 'prob': 1.0}, {'type': 'mmdet.RandomFlip', 'prob': 0.0}], [{'type': 'mmdet.LoadAnnotations', 'with_bbox': True}], [{'type': 'mmdet.PackDetInputs', 'meta_keys': ('img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor', 'pad_param', 'flip', 'flip_direction')}]]}], 'data_root': 'datasets/Box-1/', 'train_ann_file': 'train/_annotations.coco.json', 'train_data_prefix': 'train/', 'val_ann_file': 'valid/_annotations.coco.json', 'val_data_prefix': 'valid/', 'num_classes': 1, 'train_batch_size_per_gpu': 16, 'train_num_workers': 8, 'persistent_workers': True, 'anchors': [[(10, 13), (16, 30), (33, 23)], [(30, 61), (62, 45), (59, 119)], [(116, 90), (156, 198), (373, 326)]], 'base_lr': 0.01, 'max_epochs': 300, 'model_test_cfg': {'multi_label': True, 'nms_pre': 30000, 'score_thr': 0.001, 'nms': {'type': 'nms', 'iou_threshold': 0.65}, 'max_per_img': 300}, 'img_scale': (640, 640), 'dataset_type': 'YOLOv5CocoDataset', 'val_batch_size_per_gpu': 1, 'val_num_workers': 2, 'batch_shapes_cfg': {'type': 'BatchShapePolicy', 'batch_size': 1, 'img_size': 640, 'size_divisor': 32, 'extra_pad_ratio': 0.5}, 'deepen_factor': 0.33, 'widen_factor': 0.25, 'strides': [8, 16, 32], 'num_det_layers': 3, 'norm_cfg': {'type': 'BN', 'momentum': 0.03, 'eps': 0.001}, 'affine_scale': 0.5, 'loss_cls_weight': 0.5, 'loss_bbox_weight': 0.05, 'loss_obj_weight': 1.0, 'prior_match_thr': 4.0, 'obj_level_weights': [4.0, 1.0, 0.4], 'lr_factor': 0.01, 'weight_decay': 0.0005, 'save_checkpoint_intervals': 10, 'max_keep_ckpts': 3, 'model': {'type': 'YOLODetector', 'data_preprocessor': {'type': 'YOLOv5DetDataPreprocessor', 'mean': [0.0, 0.0, 0.0], 'std': [255.0, 255.0, 255.0], 'bgr_to_rgb': True}, 'backbone': {'type': 'YOLOv5CSPDarknet', 'deepen_factor': 0.33, 'widen_factor': 0.25, 'norm_cfg': {'type': 'BN', 'momentum': 0.03, 'eps': 0.001}, 'act_cfg': {'type': 'SiLU', 'inplace': True}}, 'neck': {'type': 'YOLOv5PAFPN', 'deepen_factor': 0.33, 'widen_factor': 0.25, 'in_channels': [256, 512, 1024], 'out_channels': [256, 512, 1024], 'num_csp_blocks': 3, 'norm_cfg': {'type': 'BN', 'momentum': 0.03, 'eps': 0.001}, 'act_cfg': {'type': 'SiLU', 'inplace': True}}, 'bbox_head': {'type': 'YOLOv5Head', 'head_module': {'type': 'YOLOv5HeadModule', 'num_classes': 1, 'in_channels': [256, 512, 1024], 'widen_factor': 0.25, 'featmap_strides': [8, 16, 32], 'num_base_priors': 3}, 'prior_generator': {'type': 'mmdet.YOLOAnchorGenerator', 'base_sizes': [[(10, 13), (16, 30), (33, 23)], [(30, 61), (62, 45), (59, 119)], [(116, 90), (156, 198), (373, 326)]], 'strides': [8, 16, 32]}, 'loss_cls': {'type': 'mmdet.CrossEntropyLoss', 'use_sigmoid': True, 'reduction': 'mean', 'loss_weight': 0.006250000000000001}, 'loss_bbox': {'type': 'IoULoss', 'iou_mode': 'ciou', 'bbox_format': 'xywh', 'eps': 1e-07, 'reduction': 'mean', 'loss_weight': 0.05, 'return_iou': True}, 'loss_obj': {'type': 'mmdet.CrossEntropyLoss', 'use_sigmoid': True, 'reduction': 'mean', 'loss_weight': 1.0}, 'prior_match_thr': 4.0, 'obj_level_weights': [4.0, 1.0, 0.4]}, 'test_cfg': {'multi_label': True, 'nms_pre': 30000, 'score_thr': 0.001, 'nms': {'type': 'nms', 'iou_threshold': 0.65}, 'max_per_img': 300}}, 'albu_train_transforms': [{'type': 'Blur', 'p': 0.01}, {'type': 'MedianBlur', 'p': 0.01}, {'type': 'ToGray', 'p': 0.01}, {'type': 'CLAHE', 'p': 0.01}], 'pre_transform': [{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}], 'train_pipeline': [{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Mosaic', 'img_scale': (640, 640), 'pad_val': 114.0, 'pre_transform': [{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}]}, {'type': 'YOLOv5RandomAffine', 'max_rotate_degree': 0.0, 'max_shear_degree': 0.0, 'scaling_ratio_range': (0.5, 1.5), 'border': (-320, -320), 'border_val': (114, 114, 114)}, {'type': 'mmdet.Albu', 'transforms': [{'type': 'Blur', 'p': 0.01}, {'type': 'MedianBlur', 'p': 0.01}, {'type': 'ToGray', 'p': 0.01}, {'type': 'CLAHE', 'p': 0.01}], 'bbox_params': {'type': 'BboxParams', 'format': 'pascal_voc', 'label_fields': ['gt_bboxes_labels', 'gt_ignore_flags']}, 'keymap': {'img': 'image', 'gt_bboxes': 'bboxes'}}, {'type': 'YOLOv5HSVRandomAug'}, {'type': 'mmdet.RandomFlip', 'prob': 0.5}, {'type': 'mmdet.PackDetInputs', 'meta_keys': ('img_id', 'img_path', 'ori_shape', 'img_shape', 'flip', 'flip_direction')}], 'train_dataloader': {'batch_size': 8, 'num_workers': 2, 'persistent_workers': True, 'pin_memory': True, 'sampler': {'type': 'DefaultSampler', 'shuffle': True}, 'dataset': {'type': 'YOLOv5CocoDataset', 'data_root': 'datasets/Box-1/', 'metainfo': {'classes': ('Box',), 'palette': [(220, 20, 60)]}, 'ann_file': 'train/_annotations.coco.json', 'data_prefix': {'img': 'train/'}, 'filter_cfg': {'filter_empty_gt': False, 'min_size': 32}, 'pipeline': [{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Mosaic', 'img_scale': (640, 640), 'pad_val': 114.0, 'pre_transform': [{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}]}, {'type': 'YOLOv5RandomAffine', 'max_rotate_degree': 0.0, 'max_shear_degree': 0.0, 'scaling_ratio_range': (0.5, 1.5), 'border': (-320, -320), 'border_val': (114, 114, 114)}, {'type': 'mmdet.Albu', 'transforms': [{'type': 'Blur', 'p': 0.01}, {'type': 'MedianBlur', 'p': 0.01}, {'type': 'ToGray', 'p': 0.01}, {'type': 'CLAHE', 'p': 0.01}], 'bbox_params': {'type': 'BboxParams', 'format': 'pascal_voc', 'label_fields': ['gt_bboxes_labels', 'gt_ignore_flags']}, 'keymap': {'img': 'image', 'gt_bboxes': 'bboxes'}}, {'type': 'YOLOv5HSVRandomAug'}, {'type': 'mmdet.RandomFlip', 'prob': 0.5}, {'type': 'mmdet.PackDetInputs', 'meta_keys': ('img_id', 'img_path', 'ori_shape', 'img_shape', 'flip', 'flip_direction')}]}, 'collate_fn': {'type': 'yolov5_collate'}}, 'test_pipeline': [{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'YOLOv5KeepRatioResize', 'scale': (640, 640)}, {'type': 'LetterResize', 'scale': (640, 640), 'allow_scale_up': False, 'pad_val': {'img': 114}}, {'type': 'LoadAnnotations', 'with_bbox': True, '_scope_': 'mmdet'}, {'type': 'mmdet.PackDetInputs', 'meta_keys': ('img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor', 'pad_param')}], 'val_dataloader': {'batch_size': 1, 'num_workers': 2, 'persistent_workers': True, 'pin_memory': True, 'drop_last': False, 'sampler': {'type': 'DefaultSampler', 'shuffle': False}, 'dataset': {'type': 'YOLOv5CocoDataset', 'data_root': 'datasets/Box-1/', 'metainfo': {'classes': ('Box',), 'palette': [(220, 20, 60)]}, 'test_mode': True, 'data_prefix': {'img': 'valid/'}, 'ann_file': 'valid/_annotations.coco.json', 'pipeline': [{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'YOLOv5KeepRatioResize', 'scale': (640, 640)}, {'type': 'LetterResize', 'scale': (640, 640), 'allow_scale_up': False, 'pad_val': {'img': 114}}, {'type': 'LoadAnnotations', 'with_bbox': True, '_scope_': 'mmdet'}, {'type': 'mmdet.PackDetInputs', 'meta_keys': ('img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor', 'pad_param')}], 'batch_shapes_cfg': {'type': 'BatchShapePolicy', 'batch_size': 1, 'img_size': 640, 'size_divisor': 32, 'extra_pad_ratio': 0.5}}}, 'test_dataloader': {'batch_size': 1, 'num_workers': 2, 'persistent_workers': True, 'pin_memory': True, 'drop_last': False, 'sampler': {'type': 'DefaultSampler', 'shuffle': False}, 'dataset': {'type': 'YOLOv5CocoDataset', 'data_root': 'data/coco/', 'test_mode': True, 'data_prefix': {'img': 'val2017/'}, 'ann_file': 'annotations/instances_val2017.json', 'pipeline': [{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'YOLOv5KeepRatioResize', 'scale': (640, 640)}, {'type': 'LetterResize', 'scale': (640, 640), 'allow_scale_up': False, 'pad_val': {'img': 114}}, {'type': 'LoadAnnotations', 'with_bbox': True, '_scope_': 'mmdet'}, {'type': 'mmdet.PackDetInputs', 'meta_keys': ('img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor', 'pad_param')}], 'batch_shapes_cfg': {'type': 'BatchShapePolicy', 'batch_size': 1, 'img_size': 640, 'size_divisor': 32, 'extra_pad_ratio': 0.5}}}, 'param_scheduler': None, 'optim_wrapper': {'type': 'OptimWrapper', 'optimizer': {'type': 'SGD', 'lr': 0.2, 'momentum': 0.937, 'weight_decay': 0.0005, 'nesterov': True, 'batch_size_per_gpu': 16}, 'constructor': 'YOLOv5OptimizerConstructor'}, 'custom_hooks': [{'type': 'EMAHook', 'ema_type': 'ExpMomentumEMA', 'momentum': 0.0001, 'update_buffers': True, 'strict_load': False, 'priority': 49}], 'val_evaluator': {'type': 'mmdet.CocoMetric', 'proposal_nums': (100, 1, 10), 'ann_file': 'datasets/Box-1/valid/_annotations.coco.json', 'metric': 'bbox'}, 'test_evaluator': {'type': 'mmdet.CocoMetric', 'proposal_nums': (100, 1, 10), 'ann_file': 'data/coco/annotations/instances_val2017.json', 'metric': 'bbox'}, 'train_cfg': {'type': 'EpochBasedTrainLoop', 'max_epochs': 50, 'val_interval': 1}, 'val_cfg': {'type': 'ValLoop'}, 'test_cfg': {'type': 'TestLoop'}, 'train_batch_per_gpu': 8, 'work_dir': './work_dirs/yolov5_n-v61_syncbn_fast_1xb8-300e_box/'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "488126bee5a2b9d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T16:36:22.406128Z",
     "start_time": "2024-03-13T16:36:18.809624Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/16 10:15:50 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Failed to search registry with scope \"mmyolo\" in the \"log_processor\" registry tree. As a workaround, the current \"log_processor\" registry in \"mmengine\" is used to build instance. This may cause unexpected failure when running the built modules. Please check whether \"mmyolo\" is a correct scope, or whether the registry is initialized.\n",
      "03/16 10:15:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]\n",
      "    CUDA available: True\n",
      "    MUSA available: False\n",
      "    numpy_random_seed: 561654951\n",
      "    GPU 0: NVIDIA GeForce RTX 3060 Laptop GPU\n",
      "    CUDA_HOME: /usr/local/cuda\n",
      "    NVCC: Cuda compilation tools, release 11.8, V11.8.89\n",
      "    GCC: x86_64-linux-gnu-gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
      "    PyTorch: 2.0.0+cu118\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 9.3\n",
      "  - C++ Version: 201703\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 11.8\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
      "  - CuDNN 8.7\n",
      "  - Magma 2.6.1\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "    TorchVision: 0.15.1+cu118\n",
      "    OpenCV: 4.8.0\n",
      "    MMEngine: 0.10.3\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: True\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    seed: 561654951\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "03/16 10:15:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "_backend_args = None\n",
      "_multiscale_resize_transforms = [\n",
      "    dict(\n",
      "        transforms=[\n",
      "            dict(scale=(\n",
      "                640,\n",
      "                640,\n",
      "            ), type='YOLOv5KeepRatioResize'),\n",
      "            dict(\n",
      "                allow_scale_up=False,\n",
      "                pad_val=dict(img=114),\n",
      "                scale=(\n",
      "                    640,\n",
      "                    640,\n",
      "                ),\n",
      "                type='LetterResize'),\n",
      "        ],\n",
      "        type='Compose'),\n",
      "    dict(\n",
      "        transforms=[\n",
      "            dict(scale=(\n",
      "                320,\n",
      "                320,\n",
      "            ), type='YOLOv5KeepRatioResize'),\n",
      "            dict(\n",
      "                allow_scale_up=False,\n",
      "                pad_val=dict(img=114),\n",
      "                scale=(\n",
      "                    320,\n",
      "                    320,\n",
      "                ),\n",
      "                type='LetterResize'),\n",
      "        ],\n",
      "        type='Compose'),\n",
      "    dict(\n",
      "        transforms=[\n",
      "            dict(scale=(\n",
      "                960,\n",
      "                960,\n",
      "            ), type='YOLOv5KeepRatioResize'),\n",
      "            dict(\n",
      "                allow_scale_up=False,\n",
      "                pad_val=dict(img=114),\n",
      "                scale=(\n",
      "                    960,\n",
      "                    960,\n",
      "                ),\n",
      "                type='LetterResize'),\n",
      "        ],\n",
      "        type='Compose'),\n",
      "]\n",
      "affine_scale = 0.5\n",
      "albu_train_transforms = [\n",
      "    dict(p=0.01, type='Blur'),\n",
      "    dict(p=0.01, type='MedianBlur'),\n",
      "    dict(p=0.01, type='ToGray'),\n",
      "    dict(p=0.01, type='CLAHE'),\n",
      "]\n",
      "anchors = [\n",
      "    [\n",
      "        (\n",
      "            10,\n",
      "            13,\n",
      "        ),\n",
      "        (\n",
      "            16,\n",
      "            30,\n",
      "        ),\n",
      "        (\n",
      "            33,\n",
      "            23,\n",
      "        ),\n",
      "    ],\n",
      "    [\n",
      "        (\n",
      "            30,\n",
      "            61,\n",
      "        ),\n",
      "        (\n",
      "            62,\n",
      "            45,\n",
      "        ),\n",
      "        (\n",
      "            59,\n",
      "            119,\n",
      "        ),\n",
      "    ],\n",
      "    [\n",
      "        (\n",
      "            116,\n",
      "            90,\n",
      "        ),\n",
      "        (\n",
      "            156,\n",
      "            198,\n",
      "        ),\n",
      "        (\n",
      "            373,\n",
      "            326,\n",
      "        ),\n",
      "    ],\n",
      "]\n",
      "backend_args = None\n",
      "base_lr = 0.01\n",
      "batch_shapes_cfg = dict(\n",
      "    batch_size=1,\n",
      "    extra_pad_ratio=0.5,\n",
      "    img_size=640,\n",
      "    size_divisor=32,\n",
      "    type='BatchShapePolicy')\n",
      "custom_hooks = [\n",
      "    dict(\n",
      "        ema_type='ExpMomentumEMA',\n",
      "        momentum=0.0001,\n",
      "        priority=49,\n",
      "        strict_load=False,\n",
      "        type='EMAHook',\n",
      "        update_buffers=True),\n",
      "]\n",
      "data_root = 'datasets/Box-1/'\n",
      "dataset_type = 'YOLOv5CocoDataset'\n",
      "deepen_factor = 0.33\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(\n",
      "        interval=10, max_keep_ckpts=3, save_best='auto',\n",
      "        type='CheckpointHook'),\n",
      "    param_scheduler=dict(\n",
      "        lr_factor=0.01,\n",
      "        max_epochs=50,\n",
      "        scheduler_type='linear',\n",
      "        type='YOLOv5ParamSchedulerHook'))\n",
      "default_scope = 'mmyolo'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=True,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "img_scale = (\n",
      "    640,\n",
      "    640,\n",
      ")\n",
      "img_scales = [\n",
      "    (\n",
      "        640,\n",
      "        640,\n",
      "    ),\n",
      "    (\n",
      "        320,\n",
      "        320,\n",
      "    ),\n",
      "    (\n",
      "        960,\n",
      "        960,\n",
      "    ),\n",
      "]\n",
      "load_from = None\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)\n",
      "loss_bbox_weight = 0.05\n",
      "loss_cls_weight = 0.5\n",
      "loss_obj_weight = 1.0\n",
      "lr_factor = 0.01\n",
      "max_epochs = 300\n",
      "max_keep_ckpts = 3\n",
      "model = dict(\n",
      "    backbone=dict(\n",
      "        act_cfg=dict(inplace=True, type='SiLU'),\n",
      "        deepen_factor=0.33,\n",
      "        norm_cfg=dict(eps=0.001, momentum=0.03, type='BN'),\n",
      "        type='YOLOv5CSPDarknet',\n",
      "        widen_factor=0.25),\n",
      "    bbox_head=dict(\n",
      "        head_module=dict(\n",
      "            featmap_strides=[\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "            ],\n",
      "            in_channels=[\n",
      "                256,\n",
      "                512,\n",
      "                1024,\n",
      "            ],\n",
      "            num_base_priors=3,\n",
      "            num_classes=1,\n",
      "            type='YOLOv5HeadModule',\n",
      "            widen_factor=0.25),\n",
      "        loss_bbox=dict(\n",
      "            bbox_format='xywh',\n",
      "            eps=1e-07,\n",
      "            iou_mode='ciou',\n",
      "            loss_weight=0.05,\n",
      "            reduction='mean',\n",
      "            return_iou=True,\n",
      "            type='IoULoss'),\n",
      "        loss_cls=dict(\n",
      "            loss_weight=0.006250000000000001,\n",
      "            reduction='mean',\n",
      "            type='mmdet.CrossEntropyLoss',\n",
      "            use_sigmoid=True),\n",
      "        loss_obj=dict(\n",
      "            loss_weight=1.0,\n",
      "            reduction='mean',\n",
      "            type='mmdet.CrossEntropyLoss',\n",
      "            use_sigmoid=True),\n",
      "        obj_level_weights=[\n",
      "            4.0,\n",
      "            1.0,\n",
      "            0.4,\n",
      "        ],\n",
      "        prior_generator=dict(\n",
      "            base_sizes=[\n",
      "                [\n",
      "                    (\n",
      "                        10,\n",
      "                        13,\n",
      "                    ),\n",
      "                    (\n",
      "                        16,\n",
      "                        30,\n",
      "                    ),\n",
      "                    (\n",
      "                        33,\n",
      "                        23,\n",
      "                    ),\n",
      "                ],\n",
      "                [\n",
      "                    (\n",
      "                        30,\n",
      "                        61,\n",
      "                    ),\n",
      "                    (\n",
      "                        62,\n",
      "                        45,\n",
      "                    ),\n",
      "                    (\n",
      "                        59,\n",
      "                        119,\n",
      "                    ),\n",
      "                ],\n",
      "                [\n",
      "                    (\n",
      "                        116,\n",
      "                        90,\n",
      "                    ),\n",
      "                    (\n",
      "                        156,\n",
      "                        198,\n",
      "                    ),\n",
      "                    (\n",
      "                        373,\n",
      "                        326,\n",
      "                    ),\n",
      "                ],\n",
      "            ],\n",
      "            strides=[\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "            ],\n",
      "            type='mmdet.YOLOAnchorGenerator'),\n",
      "        prior_match_thr=4.0,\n",
      "        type='YOLOv5Head'),\n",
      "    data_preprocessor=dict(\n",
      "        bgr_to_rgb=True,\n",
      "        mean=[\n",
      "            0.0,\n",
      "            0.0,\n",
      "            0.0,\n",
      "        ],\n",
      "        std=[\n",
      "            255.0,\n",
      "            255.0,\n",
      "            255.0,\n",
      "        ],\n",
      "        type='YOLOv5DetDataPreprocessor'),\n",
      "    neck=dict(\n",
      "        act_cfg=dict(inplace=True, type='SiLU'),\n",
      "        deepen_factor=0.33,\n",
      "        in_channels=[\n",
      "            256,\n",
      "            512,\n",
      "            1024,\n",
      "        ],\n",
      "        norm_cfg=dict(eps=0.001, momentum=0.03, type='BN'),\n",
      "        num_csp_blocks=3,\n",
      "        out_channels=[\n",
      "            256,\n",
      "            512,\n",
      "            1024,\n",
      "        ],\n",
      "        type='YOLOv5PAFPN',\n",
      "        widen_factor=0.25),\n",
      "    test_cfg=dict(\n",
      "        max_per_img=300,\n",
      "        multi_label=True,\n",
      "        nms=dict(iou_threshold=0.65, type='nms'),\n",
      "        nms_pre=30000,\n",
      "        score_thr=0.001),\n",
      "    type='YOLODetector')\n",
      "model_test_cfg = dict(\n",
      "    max_per_img=300,\n",
      "    multi_label=True,\n",
      "    nms=dict(iou_threshold=0.65, type='nms'),\n",
      "    nms_pre=30000,\n",
      "    score_thr=0.001)\n",
      "norm_cfg = dict(eps=0.001, momentum=0.03, type='BN')\n",
      "num_classes = 1\n",
      "num_det_layers = 3\n",
      "obj_level_weights = [\n",
      "    4.0,\n",
      "    1.0,\n",
      "    0.4,\n",
      "]\n",
      "optim_wrapper = dict(\n",
      "    constructor='YOLOv5OptimizerConstructor',\n",
      "    optimizer=dict(\n",
      "        batch_size_per_gpu=16,\n",
      "        lr=0.2,\n",
      "        momentum=0.937,\n",
      "        nesterov=True,\n",
      "        type='SGD',\n",
      "        weight_decay=0.0005),\n",
      "    type='OptimWrapper')\n",
      "param_scheduler = None\n",
      "persistent_workers = True\n",
      "pre_transform = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "]\n",
      "prior_match_thr = 4.0\n",
      "resume = True\n",
      "save_checkpoint_intervals = 10\n",
      "strides = [\n",
      "    8,\n",
      "    16,\n",
      "    32,\n",
      "]\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        ann_file='annotations/instances_val2017.json',\n",
      "        batch_shapes_cfg=dict(\n",
      "            batch_size=1,\n",
      "            extra_pad_ratio=0.5,\n",
      "            img_size=640,\n",
      "            size_divisor=32,\n",
      "            type='BatchShapePolicy'),\n",
      "        data_prefix=dict(img='val2017/'),\n",
      "        data_root='data/coco/',\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(scale=(\n",
      "                640,\n",
      "                640,\n",
      "            ), type='YOLOv5KeepRatioResize'),\n",
      "            dict(\n",
      "                allow_scale_up=False,\n",
      "                pad_val=dict(img=114),\n",
      "                scale=(\n",
      "                    640,\n",
      "                    640,\n",
      "                ),\n",
      "                type='LetterResize'),\n",
      "            dict(_scope_='mmdet', type='LoadAnnotations', with_bbox=True),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_id',\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                    'pad_param',\n",
      "                ),\n",
      "                type='mmdet.PackDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='YOLOv5CocoDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    pin_memory=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(\n",
      "    ann_file='data/coco/annotations/instances_val2017.json',\n",
      "    metric='bbox',\n",
      "    proposal_nums=(\n",
      "        100,\n",
      "        1,\n",
      "        10,\n",
      "    ),\n",
      "    type='mmdet.CocoMetric')\n",
      "test_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(scale=(\n",
      "        640,\n",
      "        640,\n",
      "    ), type='YOLOv5KeepRatioResize'),\n",
      "    dict(\n",
      "        allow_scale_up=False,\n",
      "        pad_val=dict(img=114),\n",
      "        scale=(\n",
      "            640,\n",
      "            640,\n",
      "        ),\n",
      "        type='LetterResize'),\n",
      "    dict(_scope_='mmdet', type='LoadAnnotations', with_bbox=True),\n",
      "    dict(\n",
      "        meta_keys=(\n",
      "            'img_id',\n",
      "            'img_path',\n",
      "            'ori_shape',\n",
      "            'img_shape',\n",
      "            'scale_factor',\n",
      "            'pad_param',\n",
      "        ),\n",
      "        type='mmdet.PackDetInputs'),\n",
      "]\n",
      "train_ann_file = 'train/_annotations.coco.json'\n",
      "train_batch_per_gpu = 8\n",
      "train_batch_size_per_gpu = 16\n",
      "train_cfg = dict(max_epochs=50, type='EpochBasedTrainLoop', val_interval=1)\n",
      "train_data_prefix = 'train/'\n",
      "train_dataloader = dict(\n",
      "    batch_size=8,\n",
      "    collate_fn=dict(type='yolov5_collate'),\n",
      "    dataset=dict(\n",
      "        ann_file='train/_annotations.coco.json',\n",
      "        data_prefix=dict(img='train/'),\n",
      "        data_root='datasets/Box-1/',\n",
      "        filter_cfg=dict(filter_empty_gt=False, min_size=32),\n",
      "        metainfo=dict(classes=('Box', ), palette=[\n",
      "            (\n",
      "                220,\n",
      "                20,\n",
      "                60,\n",
      "            ),\n",
      "        ]),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(\n",
      "                img_scale=(\n",
      "                    640,\n",
      "                    640,\n",
      "                ),\n",
      "                pad_val=114.0,\n",
      "                pre_transform=[\n",
      "                    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "                    dict(type='LoadAnnotations', with_bbox=True),\n",
      "                ],\n",
      "                type='Mosaic'),\n",
      "            dict(\n",
      "                border=(\n",
      "                    -320,\n",
      "                    -320,\n",
      "                ),\n",
      "                border_val=(\n",
      "                    114,\n",
      "                    114,\n",
      "                    114,\n",
      "                ),\n",
      "                max_rotate_degree=0.0,\n",
      "                max_shear_degree=0.0,\n",
      "                scaling_ratio_range=(\n",
      "                    0.5,\n",
      "                    1.5,\n",
      "                ),\n",
      "                type='YOLOv5RandomAffine'),\n",
      "            dict(\n",
      "                bbox_params=dict(\n",
      "                    format='pascal_voc',\n",
      "                    label_fields=[\n",
      "                        'gt_bboxes_labels',\n",
      "                        'gt_ignore_flags',\n",
      "                    ],\n",
      "                    type='BboxParams'),\n",
      "                keymap=dict(gt_bboxes='bboxes', img='image'),\n",
      "                transforms=[\n",
      "                    dict(p=0.01, type='Blur'),\n",
      "                    dict(p=0.01, type='MedianBlur'),\n",
      "                    dict(p=0.01, type='ToGray'),\n",
      "                    dict(p=0.01, type='CLAHE'),\n",
      "                ],\n",
      "                type='mmdet.Albu'),\n",
      "            dict(type='YOLOv5HSVRandomAug'),\n",
      "            dict(prob=0.5, type='mmdet.RandomFlip'),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_id',\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'flip',\n",
      "                    'flip_direction',\n",
      "                ),\n",
      "                type='mmdet.PackDetInputs'),\n",
      "        ],\n",
      "        type='YOLOv5CocoDataset'),\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    pin_memory=True,\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
      "train_num_workers = 8\n",
      "train_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(\n",
      "        img_scale=(\n",
      "            640,\n",
      "            640,\n",
      "        ),\n",
      "        pad_val=114.0,\n",
      "        pre_transform=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "        ],\n",
      "        type='Mosaic'),\n",
      "    dict(\n",
      "        border=(\n",
      "            -320,\n",
      "            -320,\n",
      "        ),\n",
      "        border_val=(\n",
      "            114,\n",
      "            114,\n",
      "            114,\n",
      "        ),\n",
      "        max_rotate_degree=0.0,\n",
      "        max_shear_degree=0.0,\n",
      "        scaling_ratio_range=(\n",
      "            0.5,\n",
      "            1.5,\n",
      "        ),\n",
      "        type='YOLOv5RandomAffine'),\n",
      "    dict(\n",
      "        bbox_params=dict(\n",
      "            format='pascal_voc',\n",
      "            label_fields=[\n",
      "                'gt_bboxes_labels',\n",
      "                'gt_ignore_flags',\n",
      "            ],\n",
      "            type='BboxParams'),\n",
      "        keymap=dict(gt_bboxes='bboxes', img='image'),\n",
      "        transforms=[\n",
      "            dict(p=0.01, type='Blur'),\n",
      "            dict(p=0.01, type='MedianBlur'),\n",
      "            dict(p=0.01, type='ToGray'),\n",
      "            dict(p=0.01, type='CLAHE'),\n",
      "        ],\n",
      "        type='mmdet.Albu'),\n",
      "    dict(type='YOLOv5HSVRandomAug'),\n",
      "    dict(prob=0.5, type='mmdet.RandomFlip'),\n",
      "    dict(\n",
      "        meta_keys=(\n",
      "            'img_id',\n",
      "            'img_path',\n",
      "            'ori_shape',\n",
      "            'img_shape',\n",
      "            'flip',\n",
      "            'flip_direction',\n",
      "        ),\n",
      "        type='mmdet.PackDetInputs'),\n",
      "]\n",
      "tta_model = dict(\n",
      "    tta_cfg=dict(max_per_img=300, nms=dict(iou_threshold=0.65, type='nms')),\n",
      "    type='mmdet.DetTTAModel')\n",
      "tta_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        transforms=[\n",
      "            [\n",
      "                dict(\n",
      "                    transforms=[\n",
      "                        dict(scale=(\n",
      "                            640,\n",
      "                            640,\n",
      "                        ), type='YOLOv5KeepRatioResize'),\n",
      "                        dict(\n",
      "                            allow_scale_up=False,\n",
      "                            pad_val=dict(img=114),\n",
      "                            scale=(\n",
      "                                640,\n",
      "                                640,\n",
      "                            ),\n",
      "                            type='LetterResize'),\n",
      "                    ],\n",
      "                    type='Compose'),\n",
      "                dict(\n",
      "                    transforms=[\n",
      "                        dict(scale=(\n",
      "                            320,\n",
      "                            320,\n",
      "                        ), type='YOLOv5KeepRatioResize'),\n",
      "                        dict(\n",
      "                            allow_scale_up=False,\n",
      "                            pad_val=dict(img=114),\n",
      "                            scale=(\n",
      "                                320,\n",
      "                                320,\n",
      "                            ),\n",
      "                            type='LetterResize'),\n",
      "                    ],\n",
      "                    type='Compose'),\n",
      "                dict(\n",
      "                    transforms=[\n",
      "                        dict(scale=(\n",
      "                            960,\n",
      "                            960,\n",
      "                        ), type='YOLOv5KeepRatioResize'),\n",
      "                        dict(\n",
      "                            allow_scale_up=False,\n",
      "                            pad_val=dict(img=114),\n",
      "                            scale=(\n",
      "                                960,\n",
      "                                960,\n",
      "                            ),\n",
      "                            type='LetterResize'),\n",
      "                    ],\n",
      "                    type='Compose'),\n",
      "            ],\n",
      "            [\n",
      "                dict(prob=1.0, type='mmdet.RandomFlip'),\n",
      "                dict(prob=0.0, type='mmdet.RandomFlip'),\n",
      "            ],\n",
      "            [\n",
      "                dict(type='mmdet.LoadAnnotations', with_bbox=True),\n",
      "            ],\n",
      "            [\n",
      "                dict(\n",
      "                    meta_keys=(\n",
      "                        'img_id',\n",
      "                        'img_path',\n",
      "                        'ori_shape',\n",
      "                        'img_shape',\n",
      "                        'scale_factor',\n",
      "                        'pad_param',\n",
      "                        'flip',\n",
      "                        'flip_direction',\n",
      "                    ),\n",
      "                    type='mmdet.PackDetInputs'),\n",
      "            ],\n",
      "        ],\n",
      "        type='TestTimeAug'),\n",
      "]\n",
      "val_ann_file = 'valid/_annotations.coco.json'\n",
      "val_batch_size_per_gpu = 1\n",
      "val_cfg = dict(type='ValLoop')\n",
      "val_data_prefix = 'valid/'\n",
      "val_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        ann_file='valid/_annotations.coco.json',\n",
      "        batch_shapes_cfg=dict(\n",
      "            batch_size=1,\n",
      "            extra_pad_ratio=0.5,\n",
      "            img_size=640,\n",
      "            size_divisor=32,\n",
      "            type='BatchShapePolicy'),\n",
      "        data_prefix=dict(img='valid/'),\n",
      "        data_root='datasets/Box-1/',\n",
      "        metainfo=dict(classes=('Box', ), palette=[\n",
      "            (\n",
      "                220,\n",
      "                20,\n",
      "                60,\n",
      "            ),\n",
      "        ]),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(scale=(\n",
      "                640,\n",
      "                640,\n",
      "            ), type='YOLOv5KeepRatioResize'),\n",
      "            dict(\n",
      "                allow_scale_up=False,\n",
      "                pad_val=dict(img=114),\n",
      "                scale=(\n",
      "                    640,\n",
      "                    640,\n",
      "                ),\n",
      "                type='LetterResize'),\n",
      "            dict(_scope_='mmdet', type='LoadAnnotations', with_bbox=True),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_id',\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                    'pad_param',\n",
      "                ),\n",
      "                type='mmdet.PackDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='YOLOv5CocoDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    pin_memory=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = dict(\n",
      "    ann_file='datasets/Box-1/valid/_annotations.coco.json',\n",
      "    metric='bbox',\n",
      "    proposal_nums=(\n",
      "        100,\n",
      "        1,\n",
      "        10,\n",
      "    ),\n",
      "    type='mmdet.CocoMetric')\n",
      "val_num_workers = 2\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    name='visualizer',\n",
      "    type='mmdet.DetLocalVisualizer',\n",
      "    vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "    ])\n",
      "weight_decay = 0.0005\n",
      "widen_factor = 0.25\n",
      "work_dir = './work_dirs/yolov5_n-v61_syncbn_fast_1xb8-300e_box/'\n",
      "\n",
      "!!!You are using `YOLOv5Head` with num_classes == 1. The loss_cls will be 0. This is a normal phenomenon.\n",
      "03/16 10:15:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "03/16 10:15:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(49          ) EMAHook                            \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_load_checkpoint:\n",
      "(49          ) EMAHook                            \n",
      " -------------------- \n",
      "before_train:\n",
      "(9           ) YOLOv5ParamSchedulerHook           \n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(49          ) EMAHook                            \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(9           ) YOLOv5ParamSchedulerHook           \n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(9           ) YOLOv5ParamSchedulerHook           \n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(49          ) EMAHook                            \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(9           ) YOLOv5ParamSchedulerHook           \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(49          ) EMAHook                            \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(9           ) YOLOv5ParamSchedulerHook           \n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(49          ) EMAHook                            \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_save_checkpoint:\n",
      "(49          ) EMAHook                            \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(49          ) EMAHook                            \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(49          ) EMAHook                            \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "03/16 10:15:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Optimizer groups: 60 .bias, 60 conv.weight, 57 other\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Did not find last_checkpoint to be resumed.\n",
      "03/16 10:15:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Auto resumed from the latest checkpoint None.\n",
      "03/16 10:15:54 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
      "03/16 10:15:54 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n",
      "03/16 10:15:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /workspace/objectdet/work_dirs/yolov5_n-v61_syncbn_fast_1xb8-300e_box.\n",
      "03/16 10:15:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][10/58]  base_lr: 2.0000e-01 lr: 1.8000e-03  eta: 0:18:05  time: 0.3757  data_time: 0.0368  memory: 1978  loss: 1.4414  loss_cls: 0.0000  loss_obj: 0.5807  loss_bbox: 0.8607\n",
      "03/16 10:15:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][20/58]  base_lr: 2.0000e-01 lr: 3.8000e-03  eta: 0:11:50  time: 0.2467  data_time: 0.0239  memory: 1339  loss: 1.4760  loss_cls: 0.0000  loss_obj: 0.6311  loss_bbox: 0.8450\n",
      "03/16 10:16:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][30/58]  base_lr: 2.0000e-01 lr: 5.8000e-03  eta: 0:09:37  time: 0.2013  data_time: 0.0200  memory: 1339  loss: 1.4777  loss_cls: 0.0000  loss_obj: 0.6501  loss_bbox: 0.8276\n",
      "03/16 10:16:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][40/58]  base_lr: 2.0000e-01 lr: 7.8000e-03  eta: 0:08:26  time: 0.1770  data_time: 0.0183  memory: 1339  loss: 1.4695  loss_cls: 0.0000  loss_obj: 0.6610  loss_bbox: 0.8085\n",
      "03/16 10:16:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][50/58]  base_lr: 2.0000e-01 lr: 9.8000e-03  eta: 0:07:31  time: 0.1584  data_time: 0.0149  memory: 1339  loss: 1.4575  loss_cls: 0.0000  loss_obj: 0.6631  loss_bbox: 0.7944\n",
      "03/16 10:16:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: yolov5_n-v61_syncbn_fast_8xb16-300e_coco_20240316_101549\n",
      "03/16 10:16:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [1][ 10/131]    eta: 0:00:07  time: 0.0615  data_time: 0.0050  memory: 1551  \n",
      "03/16 10:16:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [1][ 20/131]    eta: 0:00:04  time: 0.0421  data_time: 0.0028  memory: 167  \n",
      "03/16 10:16:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [1][ 30/131]    eta: 0:00:03  time: 0.0356  data_time: 0.0021  memory: 167  \n",
      "03/16 10:16:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [1][ 40/131]    eta: 0:00:02  time: 0.0326  data_time: 0.0017  memory: 167  \n",
      "03/16 10:16:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [1][ 50/131]    eta: 0:00:02  time: 0.0308  data_time: 0.0015  memory: 167  \n",
      "03/16 10:16:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [1][ 60/131]    eta: 0:00:02  time: 0.0230  data_time: 0.0006  memory: 167  \n",
      "03/16 10:16:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [1][ 70/131]    eta: 0:00:01  time: 0.0229  data_time: 0.0006  memory: 167  \n",
      "03/16 10:16:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [1][ 80/131]    eta: 0:00:01  time: 0.0230  data_time: 0.0006  memory: 167  \n",
      "03/16 10:16:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [1][ 90/131]    eta: 0:00:01  time: 0.0230  data_time: 0.0006  memory: 167  \n",
      "03/16 10:16:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [1][100/131]    eta: 0:00:00  time: 0.0229  data_time: 0.0006  memory: 167  \n",
      "03/16 10:16:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [1][110/131]    eta: 0:00:00  time: 0.0230  data_time: 0.0006  memory: 167  \n",
      "03/16 10:16:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [1][120/131]    eta: 0:00:00  time: 0.0232  data_time: 0.0006  memory: 167  \n",
      "03/16 10:16:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [1][130/131]    eta: 0:00:00  time: 0.0229  data_time: 0.0005  memory: 167  \n",
      "03/16 10:16:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.17s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.90s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.05s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.003\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.064\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.084\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.002\n",
      "03/16 10:16:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - bbox_mAP_copypaste: 0.000 0.002 0.000 -1.000 0.001 0.003\n",
      "03/16 10:16:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][131/131]    coco/bbox_mAP: 0.0000  coco/bbox_mAP_50: 0.0020  coco/bbox_mAP_75: 0.0000  coco/bbox_mAP_s: -1.0000  coco/bbox_mAP_m: 0.0010  coco/bbox_mAP_l: 0.0030  data_time: 0.0009  time: 0.0259\n",
      "03/16 10:16:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.0000 coco/bbox_mAP at 1 epoch is saved to best_coco_bbox_mAP_epoch_1.pth.\n",
      "03/16 10:16:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][10/58]  base_lr: 2.0000e-01 lr: 1.3135e-02  eta: 0:07:45  time: 0.1290  data_time: 0.0104  memory: 1340  loss: 1.3887  loss_cls: 0.0000  loss_obj: 0.6487  loss_bbox: 0.7400\n",
      "03/16 10:16:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][20/58]  base_lr: 2.0000e-01 lr: 1.5095e-02  eta: 0:07:14  time: 0.1245  data_time: 0.0092  memory: 1340  loss: 1.3998  loss_cls: 0.0000  loss_obj: 0.6768  loss_bbox: 0.7231\n",
      "03/16 10:16:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][30/58]  base_lr: 2.0000e-01 lr: 1.7055e-02  eta: 0:06:50  time: 0.1194  data_time: 0.0064  memory: 1340  loss: 1.3882  loss_cls: 0.0000  loss_obj: 0.6743  loss_bbox: 0.7140\n",
      "03/16 10:16:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][40/58]  base_lr: 2.0000e-01 lr: 1.9016e-02  eta: 0:06:32  time: 0.1193  data_time: 0.0065  memory: 1340  loss: 1.3918  loss_cls: 0.0000  loss_obj: 0.6898  loss_bbox: 0.7020\n",
      "03/16 10:16:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][50/58]  base_lr: 2.0000e-01 lr: 2.0976e-02  eta: 0:06:17  time: 0.0941  data_time: 0.0055  memory: 1340  loss: 1.4233  loss_cls: 0.0000  loss_obj: 0.7199  loss_bbox: 0.7035\n",
      "03/16 10:16:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: yolov5_n-v61_syncbn_fast_8xb16-300e_coco_20240316_101549\n",
      "03/16 10:16:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [2][ 10/131]    eta: 0:00:02  time: 0.0228  data_time: 0.0007  memory: 1340  \n",
      "03/16 10:16:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [2][ 20/131]    eta: 0:00:02  time: 0.0224  data_time: 0.0007  memory: 168  \n",
      "03/16 10:16:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [2][ 30/131]    eta: 0:00:02  time: 0.0225  data_time: 0.0007  memory: 168  \n",
      "03/16 10:16:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [2][ 40/131]    eta: 0:00:02  time: 0.0222  data_time: 0.0007  memory: 168  \n",
      "03/16 10:16:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [2][ 50/131]    eta: 0:00:01  time: 0.0220  data_time: 0.0007  memory: 168  \n",
      "03/16 10:16:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [2][ 60/131]    eta: 0:00:01  time: 0.0219  data_time: 0.0006  memory: 168  \n",
      "03/16 10:16:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [2][ 70/131]    eta: 0:00:01  time: 0.0219  data_time: 0.0006  memory: 168  \n",
      "03/16 10:16:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [2][ 80/131]    eta: 0:00:01  time: 0.0216  data_time: 0.0006  memory: 168  \n",
      "03/16 10:16:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [2][ 90/131]    eta: 0:00:00  time: 0.0216  data_time: 0.0006  memory: 168  \n",
      "03/16 10:16:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [2][100/131]    eta: 0:00:00  time: 0.0219  data_time: 0.0006  memory: 168  \n",
      "03/16 10:16:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [2][110/131]    eta: 0:00:00  time: 0.0219  data_time: 0.0006  memory: 168  \n",
      "03/16 10:16:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [2][120/131]    eta: 0:00:00  time: 0.0220  data_time: 0.0006  memory: 168  \n",
      "03/16 10:16:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [2][130/131]    eta: 0:00:00  time: 0.0220  data_time: 0.0006  memory: 168  \n",
      "03/16 10:16:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.19s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmmengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrunner\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Runner\n\u001b[1;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m Runner\u001b[38;5;241m.\u001b[39mfrom_cfg(cfg)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/objectdet/.venv/lib/python3.10/site-packages/mmengine/runner/runner.py:1777\u001b[0m, in \u001b[0;36mRunner.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1773\u001b[0m \u001b[38;5;66;03m# Maybe compile the model according to options in self.cfg.compile\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;66;03m# This must be called **AFTER** model has been wrapped.\u001b[39;00m\n\u001b[1;32m   1775\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_compile(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_step\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1777\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   1778\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_hook(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_run\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m/workspace/objectdet/.venv/lib/python3.10/site-packages/mmengine/runner/loops.py:102\u001b[0m, in \u001b[0;36mEpochBasedTrainLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decide_current_val_interval()\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunner\u001b[38;5;241m.\u001b[39mval_loop \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    100\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_epoch \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_begin\n\u001b[1;32m    101\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_interval \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m--> 102\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mval_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunner\u001b[38;5;241m.\u001b[39mcall_hook(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_train\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunner\u001b[38;5;241m.\u001b[39mmodel\n",
      "File \u001b[0;32m/workspace/objectdet/.venv/lib/python3.10/site-packages/mmengine/runner/loops.py:374\u001b[0m, in \u001b[0;36mValLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_iter(idx, data_batch)\n\u001b[1;32m    373\u001b[0m \u001b[38;5;66;03m# compute metrics\u001b[39;00m\n\u001b[0;32m--> 374\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunner\u001b[38;5;241m.\u001b[39mcall_hook(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_val_epoch\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39mmetrics)\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunner\u001b[38;5;241m.\u001b[39mcall_hook(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_val\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/workspace/objectdet/.venv/lib/python3.10/site-packages/mmengine/evaluator/evaluator.py:79\u001b[0m, in \u001b[0;36mEvaluator.evaluate\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m     77\u001b[0m metrics \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m metric \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetrics:\n\u001b[0;32m---> 79\u001b[0m     _results \u001b[38;5;241m=\u001b[39m \u001b[43mmetric\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;66;03m# Check metric name conflicts\u001b[39;00m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m _results\u001b[38;5;241m.\u001b[39mkeys():\n",
      "File \u001b[0;32m/workspace/objectdet/.venv/lib/python3.10/site-packages/mmengine/evaluator/metric.py:133\u001b[0m, in \u001b[0;36mBaseMetric.evaluate\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_main_process():\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;66;03m# cast all tensors in results list to cpu\u001b[39;00m\n\u001b[1;32m    132\u001b[0m     results \u001b[38;5;241m=\u001b[39m _to_cpu(results)\n\u001b[0;32m--> 133\u001b[0m     _metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;66;03m# Add prefix to metric names\u001b[39;00m\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprefix:\n",
      "File \u001b[0;32m/workspace/objectdet/.venv/lib/python3.10/site-packages/mmdet/evaluation/metrics/coco_metric.py:517\u001b[0m, in \u001b[0;36mCocoMetric.compute_metrics\u001b[0;34m(self, results)\u001b[0m\n\u001b[1;32m    515\u001b[0m         eval_results[item] \u001b[38;5;241m=\u001b[39m val\n\u001b[1;32m    516\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 517\u001b[0m     \u001b[43mcoco_eval\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    518\u001b[0m     coco_eval\u001b[38;5;241m.\u001b[39maccumulate()\n\u001b[1;32m    519\u001b[0m     coco_eval\u001b[38;5;241m.\u001b[39msummarize()\n",
      "File \u001b[0;32m/workspace/objectdet/.venv/lib/python3.10/site-packages/pycocotools/cocoeval.py:154\u001b[0m, in \u001b[0;36mCOCOeval.evaluate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    152\u001b[0m evaluateImg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluateImg\n\u001b[1;32m    153\u001b[0m maxDet \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mmaxDets[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m--> 154\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevalImgs \u001b[38;5;241m=\u001b[39m [evaluateImg(imgId, catId, areaRng, maxDet)\n\u001b[1;32m    155\u001b[0m          \u001b[38;5;28;01mfor\u001b[39;00m catId \u001b[38;5;129;01min\u001b[39;00m catIds\n\u001b[1;32m    156\u001b[0m          \u001b[38;5;28;01mfor\u001b[39;00m areaRng \u001b[38;5;129;01min\u001b[39;00m p\u001b[38;5;241m.\u001b[39mareaRng\n\u001b[1;32m    157\u001b[0m          \u001b[38;5;28;01mfor\u001b[39;00m imgId \u001b[38;5;129;01min\u001b[39;00m p\u001b[38;5;241m.\u001b[39mimgIds\n\u001b[1;32m    158\u001b[0m      ]\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_paramsEval \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n\u001b[1;32m    160\u001b[0m toc \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[0;32m/workspace/objectdet/.venv/lib/python3.10/site-packages/pycocotools/cocoeval.py:154\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    152\u001b[0m evaluateImg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluateImg\n\u001b[1;32m    153\u001b[0m maxDet \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mmaxDets[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m--> 154\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevalImgs \u001b[38;5;241m=\u001b[39m [\u001b[43mevaluateImg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimgId\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatId\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mareaRng\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxDet\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    155\u001b[0m          \u001b[38;5;28;01mfor\u001b[39;00m catId \u001b[38;5;129;01min\u001b[39;00m catIds\n\u001b[1;32m    156\u001b[0m          \u001b[38;5;28;01mfor\u001b[39;00m areaRng \u001b[38;5;129;01min\u001b[39;00m p\u001b[38;5;241m.\u001b[39mareaRng\n\u001b[1;32m    157\u001b[0m          \u001b[38;5;28;01mfor\u001b[39;00m imgId \u001b[38;5;129;01min\u001b[39;00m p\u001b[38;5;241m.\u001b[39mimgIds\n\u001b[1;32m    158\u001b[0m      ]\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_paramsEval \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n\u001b[1;32m    160\u001b[0m toc \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[0;32m/workspace/objectdet/.venv/lib/python3.10/site-packages/pycocotools/cocoeval.py:278\u001b[0m, in \u001b[0;36mCOCOeval.evaluateImg\u001b[0;34m(self, imgId, catId, aRng, maxDet)\u001b[0m\n\u001b[1;32m    276\u001b[0m iou \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m([t,\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1e-10\u001b[39m])\n\u001b[1;32m    277\u001b[0m m   \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 278\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m gind, g \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgt\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;66;03m# if this gt already matched, and not a crowd, continue\u001b[39;00m\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gtm[tind,gind]\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m iscrowd[gind]:\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from mmengine.runner import Runner\n",
    "\n",
    "model = Runner.from_cfg(cfg)\n",
    "\n",
    "model.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
